{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A practical introduction to Pandas\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been asked to *analyze an otp dataset*, without much more information. This kind of scenario is more common than you might imagine!\n",
    "\n",
    "## 1) Quickly examine the files in ~/Data/us_dot/otp. What do they contain, in both technical and functional terms? (Use any tool you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "your_path_to_zips = '/home/dsc/Data/us_dot/otp'\n",
    "my_path_to_zips = '--/../home/dsc/Data/us_dot/otp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc/Repositories/master-data-science-nacho/trabajos_jupiter/ejercicio_clase_Phyton\r\n"
     ]
    }
   ],
   "source": [
    "!pwd #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On_Time_On_Time_Performance_2015_1.zip\tOn_Time_On_Time_Performance_2015_5.zip\r\n",
      "On_Time_On_Time_Performance_2015_2.zip\tOn_Time_On_Time_Performance_2015_6.zip\r\n",
      "On_Time_On_Time_Performance_2015_3.zip\tOn_Time_On_Time_Performance_2015_7.zip\r\n",
      "On_Time_On_Time_Performance_2015_4.zip\tOn_Time_On_Time_Performance_2015_8.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls $your_path_to_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/dsc/Data/us_dot/otp/On_Time_On_Time_Performance_2015_1.zip\r\n",
      "  Length      Date    Time    Name\r\n",
      "---------  ---------- -----   ----\r\n",
      "    12054  04-16-2015 20:02   readme.html\r\n",
      "---------                     -------\r\n",
      "    12054                     1 file\r\n"
     ]
    }
   ],
   "source": [
    "! unzip -l $your_path_to_zips/On_Time_On_Time_Performance_2015_1.zip readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/dsc/Data/us_dot/otp/On_Time_On_Time_Performance_2015_1.zip\n",
      "  inflating: On_Time_On_Time_Performance_2015_1.csv  \n"
     ]
    }
   ],
   "source": [
    "filename = 'On_Time_On_Time_Performance_2015_1'\n",
    "!unzip -o $your_path_to_zips/{filename}.zip {filename}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Year\",\"Quarter\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"FlightDate\",\"UniqueCarrier\",\"AirlineID\",\"Carrier\",\"TailNum\",\"FlightNum\",\"OriginAirportID\",\"OriginAirportSeqID\",\"OriginCityMarketID\",\"Origin\",\"OriginCityName\",\"OriginState\",\"OriginStateFips\",\"OriginStateName\",\"OriginWac\",\"DestAirportID\",\"DestAirportSeqID\",\"DestCityMarketID\",\"Dest\",\"DestCityName\",\"DestState\",\"DestStateFips\",\"DestStateName\",\"DestWac\",\"CRSDepTime\",\"DepTime\",\"DepDelay\",\"DepDelayMinutes\",\"DepDel15\",\"DepartureDelayGroups\",\"DepTimeBlk\",\"TaxiOut\",\"WheelsOff\",\"WheelsOn\",\"TaxiIn\",\"CRSArrTime\",\"ArrTime\",\"ArrDelay\",\"ArrDelayMinutes\",\"ArrDel15\",\"ArrivalDelayGroups\",\"ArrTimeBlk\",\"Cancelled\",\"CancellationCode\",\"Diverted\",\"CRSElapsedTime\",\"ActualElapsedTime\",\"AirTime\",\"Flights\",\"Distance\",\"DistanceGroup\",\"CarrierDelay\",\"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\"LateAircraftDelay\",\"FirstDepTime\",\"TotalAddGTime\",\"LongestAddGTime\",\"DivAirportLandings\",\"DivReachedDest\",\"DivActualElapsedTime\",\"DivArrDelay\",\"DivDistance\",\"Div1Airport\",\"Div1AirportID\",\"Div1AirportSeqID\",\"Div1WheelsOn\",\"Div1TotalGTime\",\"Div1LongestGTime\",\"Div1WheelsOff\",\"Div1TailNum\",\"Div2Airport\",\"Div2AirportID\",\"Div2AirportSeqID\",\"Div2WheelsOn\",\"Div2TotalGTime\",\"Div2LongestGTime\",\"Div2WheelsOff\",\"Div2TailNum\",\"Div3Airport\",\"Div3AirportID\",\"Div3AirportSeqID\",\"Div3WheelsOn\",\"Div3TotalGTime\",\"Div3LongestGTime\",\"Div3WheelsOff\",\"Div3TailNum\",\"Div4Airport\",\"Div4AirportID\",\"Div4AirportSeqID\",\"Div4WheelsOn\",\"Div4TotalGTime\",\"Div4LongestGTime\",\"Div4WheelsOff\",\"Div4TailNum\",\"Div5Airport\",\"Div5AirportID\",\"Div5AirportSeqID\",\"Div5WheelsOn\",\"Div5TotalGTime\",\"Div5LongestGTime\",\"Div5WheelsOff\",\"Div5TailNum\",\r\n",
      "2015,1,1,1,4,2015-01-01,\"AA\",19805,\"AA\",\"N787AA\",\"1\",12478,1247802,31703,\"JFK\",\"New York, NY\",\"NY\",\"36\",\"New York\",22,12892,1289203,32575,\"LAX\",\"Los Angeles, CA\",\"CA\",\"06\",\"California\",91,\"0900\",\"0855\",-5.00,0.00,0.00,-1,\"0900-0959\",17.00,\"0912\",\"1230\",7.00,\"1230\",\"1237\",7.00,7.00,0.00,0,\"1200-1259\",0.00,\"\",0.00,390.00,402.00,378.00,1.00,2475.00,10,,,,,,\"\",,,0,,,,,\"\",,,\"\",,,\"\",\"\",\"\",,,\"\",,,\"\",\"\",\"\",,,\"\",,,\"\",\"\",\"\",,,\"\",,,\"\",\"\",\"\",,,\"\",,,\"\",\"\",\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 On_Time_On_Time_Performance_2015_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc/Repositories/master-data-science-nacho/trabajos_jupiter/ejercicio_clase_Phyton\n"
     ]
    }
   ],
   "source": [
    "cd /home/dsc/Repositories/master-data-science-nacho/trabajos_jupiter/ejercicio_clase_Phyton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 298036\r\n",
      "-rw-rw-r-- 1 dsc dsc    178724 Jan 16 20:59 01-numpy_pandas_introduction_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc    217721 Jan 18 19:34 02-loading_and_saving_data_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc     51086 Jan 19 18:44 03-merge_concatenate_transform_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc     23479 Jan 19 20:01 04-group_by_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc    110118 Jan 20 09:22 05-visualization_introduction_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc     29598 Jan 20 12:17 06-intro_to_pandas_practical_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc     13027 Jan 17 20:32 07-ejercicios_de_repaso_de_pandas_blank.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc    230036 Jan 17 20:32 07-ejercicios_de_repaso_de_pandas.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc      7940 Jan 14 20:50 2017-12-15-notebook.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc    684027 Jan 14 20:50 2017-12-16-notebook.ipynb\r\n",
      "-rw-r--r-- 1 dsc dsc  51575427 Nov  8  2015 914310910_T_T100_SEGMENT_ALL_CARRIER_2015_All.csv\r\n",
      "-rw-r--r-- 1 dsc dsc      4341 Nov  8  2015 914310910_T_T100_SEGMENT_ALL_CARRIER_ReadMe.csv\r\n",
      "-rw-r--r-- 1 dsc dsc      4268 Nov  8  2015 914310910_T_T100_SEGMENT_ALL_CARRIER_Terms.csv\r\n",
      "-rw-rw-r-- 1 dsc dsc    702954 Jan 17 21:30 D1-numpy_pandas_introduction2.html\r\n",
      "-rw-rw-r-- 1 dsc dsc    387136 Jan 16 21:11 D1-numpy_pandas_introduction.ipynb\r\n",
      "-rw-rw-r-- 1 dsc dsc    166680 Jan 18 19:48 D2-loading_and_saving_data_blank.ipynb\r\n",
      "-rw-r--r-- 1 dsc dsc  38543360 Jan 18 18:40 example.db\r\n",
      "-rw-rw-r-- 1 dsc dsc    570880 Jan 18 18:39 excel_out.xls\r\n",
      "-rw-r--r-- 1 dsc dsc 211633432 Apr 16  2015 On_Time_On_Time_Performance_2015_1.csv\r\n",
      "-rw-rw-r-- 1 dsc dsc      3841 Jan 18 19:32 sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"readme.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f24cbd69f28>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "# help(IFrame)\n",
    "\n",
    "IFrame('readme.html', 800, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='readme.html' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme = open('readme.html')\n",
    "readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-75-869edd285a84>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-869edd285a84>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_csv_file = my_zip_file.open{filename } + {'.csv'}\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from zipfile import Zipfile\n",
    "your_zip_file = ZipFile(my_path_to_zips + filename + '.zip')\n",
    "my_csv_file = my_zip_file.open{filename } + {'.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use ('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-869edd285a84>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-71-869edd285a84>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_csv_file = my_zip_file.open{filename } + {'.csv'}\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from zipfile import Zipfile\n",
    "your_zip_file = ZipFile(my_path_to_zips + filename + '.zip')\n",
    "my_csv_file = my_zip_file.open{filename } + {'.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_zip_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-9428a91846ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_csv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_zip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'my_zip_file' is not defined"
     ]
    }
   ],
   "source": [
    "my_csv_file = my_zip_file.open(filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-1a03d0db8262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_cv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_cv(my_csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open ('./914310910_T_T100_SEGEMENT_ALLCARRIER_ReadMe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.readlines()\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(my_csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are going to begin using the shell from within this notebook, with the ! notation:\n",
    "\n",
    "A ! sign before a line tells the notebook to send that line straight away to the underlying OS. \n",
    "\n",
    "\\* Note that we can substitute python variables into the shell command. We do that by surrounding the name of the variable with curly braces ({}). That's what we are going to do with the `path_to_files` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what the files contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, it has a readme! Always good to read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the readme to the current directory\n",
    "\n",
    "Use the shell\n",
    "\n",
    "Remember, since the zip file contains several compressed files, we need to specify which one we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the beginning of the readme file\n",
    "\n",
    "using the shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The readme file is html. Luckily, we are working in an html environment. \n",
    "\n",
    "### Display the contents of `readme.html` within the notebook\n",
    "(Hint: check out [IPython.display.IFrame](https://ipython.org/ipython-doc/3/api/generated/IPython.display.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's some very good documentation!\n",
    "\n",
    "### Summary: \n",
    "\n",
    "The files within the zip are \" quoted csv's. They contain information on timeliness of departures in the US, at the departure level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty unreadable, so we go for a tool designed specifically for tabular data: **pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some of the data (one of the files) into memory as a pandas dataframe. What functions do you need to use?\n",
    "\n",
    "Pro tip: there is no need to decompress the whole file. Check out zipfile.ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, open a connection to one of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip_file is a connection to the compressed file, the .zip. We can use it to open a connection to one of the files it contains, which will behave like a normal uncompressed file that we had opened with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we're ready to load the file into memory as a pandas dataframe. Remember to close the connections to the files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start examining the data: show the beginning of the file. How many records does it contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the data\n",
    "\n",
    "The table is quite wide, and it seems that there are many columns without much data. Which, exactly, are those? (let's consider empty a column that doesn't contain at least 1000 records, arbitrarily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df.count() > 10000\n",
    "not_that_empty_colums = df.columns[mask]\n",
    "\n",
    "df2 = df[not_that_empty_colums]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It seems that the \"diverted\" fields, after the first, are often empty. No big surprise, since not that many flights must be diverted more than once in a month. Let's drop those columns, since we are not that interested in those, at least for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have eliminated some inconvenient data columns, let's have a look at the rest: let's loook at how the location data is encoded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "First, generate a list of the columns that have 'Origin' in their name\n",
    "\n",
    "Second, show a sample of the values that those columns take.\n",
    "\n",
    "Hint: we are going to use the str attribute of Series and Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_col_names = df3.columns.str.contains('Origin')\n",
    "originals_colums = df3.columns{origin_col_names}\n",
    "\n",
    "df3{origin_cols}.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So much redundant information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast forward\n",
    "\n",
    "Just taking out the redundant columns would take a while, so let's jump ahead with this list of interesting columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting columns and parsing dates and times\n",
    "\n",
    "Hurray! we have almost cleaned our dataset. Soon we will begin to do some actual work with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlightDate          object\n",
       "DayOfWeek            int64\n",
       "Carrier             object\n",
       "TailNum             object\n",
       "FlightNum            int64\n",
       "Origin              object\n",
       "OriginCityName      object\n",
       "OriginStateName     object\n",
       "Dest                object\n",
       "DestCityName        object\n",
       "DestStateName       object\n",
       "DepTime            float64\n",
       "DepDelay           float64\n",
       "AirTime            float64\n",
       "Distance           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas interpreted the Deptime column as ints and the FlighDate column as strings. We want to combine them and parse them into a DateTime column, so that we can use them properly as datetimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step:\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Define a function that will parse our int hours into a reasonable format (\"HH:MM\"). It should take only one int hour and return the appropriate representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-03 00:00:00')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2018-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float_to_timestring(input_float):\n",
    "    minutes = input_float % 100\n",
    "    hours = input_float// 100\n",
    "    string_representation = '%.2d:%.2d' % (horas,minutes)\n",
    "    \n",
    "df4[['flightDate', 'DepTime']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use that function to build datetime strings that we will then pass to pd.to_datetime, with a format we will specify. Let's do that\n",
    "\n",
    "Hint: Check out [pd.to_datetime's documentatoin](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html) for info on the acceptable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Overwrite the 'DepTime' column with its version in the proper format\n",
    "\n",
    "Hint: Before overwriting your column in the dataframe, make sure that everything works by assigning the modified column to a Series variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Now, create a DepDateTime with the proper type using `pd.to_datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the types, see if everything is in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally clean! Let's start to do some preliminary work on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Find the biggest delays. \n",
    "\n",
    "How would you find the 5 maximum delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4['DepDelay'].sort_values(ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.sort_values(by='DepDelay',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "What was the average delay for this month? Standard deviation and typical value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4['DEapDelay'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.mean()['DEapDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also: a quick look at the correlation between the numerical variables is extremely easy with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "What is the plane that has the highest average delay? We'll first group by tail number (the *license plate* of a plane) and then calculate the relevant statistic for each group (group of *departures*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, but those numbers smell like these planes had only a few, very delayed, departures! how can we count the number of departures *and* calculate the average delay at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! now, let's look at the average delay of the planes with some departures (let's say, at least 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Show cities by descending number of airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "There are several ways in which we could go about plotting this dataset in order to get acquainted with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, do the delays have a relationship with the number of departures a plane does?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Do a scatter plot with matplotlib. Check the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty impossible to see anything in there. Maybe a different kind of plottting is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Plot the distribution of delays as a histogram, both with a linear and a logarithmic scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another question:\n",
    "\n",
    "how do the delays stack over the course of the day? We are going to look at it by plotting the distribution of delays for each hour of the day. The very best way to compare distributions side by side is a boxplot, so we'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide `plt.boxplot()` with a sequence that contains 24 elements. Each of those will be a sequence containing every individual delay for one hour of the day. We'll need, therefore, to extract hours of the day for each departure and group based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything looks ok! let's plot this thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
